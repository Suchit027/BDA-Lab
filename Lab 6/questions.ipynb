{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d36198-9612-4e4f-90de-c6c192f857dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/07 15:26:57 WARN Utils: Your hostname, DESKTOP-2J74AJH resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/09/07 15:26:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/07 15:26:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/07 15:26:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/09/07 15:26:58 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/09/07 15:26:58 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/09/07 15:26:58 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "24/09/07 15:26:58 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "24/09/07 15:26:58 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "24/09/07 15:26:58 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkSession.builder.appName('decision trees').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b75754-d18c-4e67-aed6-04f9d9f910e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:===>                                                     (1 + 15) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: integer (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: integer (nullable = true)\n",
      " |-- _c7: integer (nullable = true)\n",
      " |-- _c8: integer (nullable = true)\n",
      " |-- _c9: integer (nullable = true)\n",
      " |-- _c10: integer (nullable = true)\n",
      " |-- _c11: integer (nullable = true)\n",
      " |-- _c12: integer (nullable = true)\n",
      " |-- _c13: integer (nullable = true)\n",
      " |-- _c14: integer (nullable = true)\n",
      " |-- _c15: integer (nullable = true)\n",
      " |-- _c16: integer (nullable = true)\n",
      " |-- _c17: integer (nullable = true)\n",
      " |-- _c18: integer (nullable = true)\n",
      " |-- _c19: integer (nullable = true)\n",
      " |-- _c20: integer (nullable = true)\n",
      " |-- _c21: integer (nullable = true)\n",
      " |-- _c22: integer (nullable = true)\n",
      " |-- _c23: integer (nullable = true)\n",
      " |-- _c24: integer (nullable = true)\n",
      " |-- _c25: integer (nullable = true)\n",
      " |-- _c26: integer (nullable = true)\n",
      " |-- _c27: integer (nullable = true)\n",
      " |-- _c28: integer (nullable = true)\n",
      " |-- _c29: integer (nullable = true)\n",
      " |-- _c30: integer (nullable = true)\n",
      " |-- _c31: integer (nullable = true)\n",
      " |-- _c32: integer (nullable = true)\n",
      " |-- _c33: integer (nullable = true)\n",
      " |-- _c34: integer (nullable = true)\n",
      " |-- _c35: integer (nullable = true)\n",
      " |-- _c36: integer (nullable = true)\n",
      " |-- _c37: integer (nullable = true)\n",
      " |-- _c38: integer (nullable = true)\n",
      " |-- _c39: integer (nullable = true)\n",
      " |-- _c40: integer (nullable = true)\n",
      " |-- _c41: integer (nullable = true)\n",
      " |-- _c42: integer (nullable = true)\n",
      " |-- _c43: integer (nullable = true)\n",
      " |-- _c44: integer (nullable = true)\n",
      " |-- _c45: integer (nullable = true)\n",
      " |-- _c46: integer (nullable = true)\n",
      " |-- _c47: integer (nullable = true)\n",
      " |-- _c48: integer (nullable = true)\n",
      " |-- _c49: integer (nullable = true)\n",
      " |-- _c50: integer (nullable = true)\n",
      " |-- _c51: integer (nullable = true)\n",
      " |-- _c52: integer (nullable = true)\n",
      " |-- _c53: integer (nullable = true)\n",
      " |-- _c54: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_without_header = sc.read.option('inferSchema', True).option('header', False).csv('covtype.csv')\n",
    "data_without_header.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba996742-ed03-488b-ae7d-e71c5350e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "colnames =  [\"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\", \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\", \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\", \"Horizontal_Distance_To_Fire_Points\"]\n",
    "colnames = colnames + [f'Wilderness_Area_{i}' for i in range(4)]\n",
    "colnames = colnames + [f'Soil_Type{i}' for i in range(40)] + ['Cover_Type']\n",
    "\n",
    "data = data_without_header.toDF(*colnames)\n",
    "data = data.withColumn('Cover_Type', col('Cover_Type').cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae979901-167b-4d5b-b623-4b337a4c456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b6528ed-fb74-48d8-a609-a3872597564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "input_cols = colnames[: len(colnames) - 1]\n",
    "vector_assembler = VectorAssembler(inputCols= input_cols, outputCol = 'featureVector')\n",
    "assembled_train = vector_assembler.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9757d08-1f3a-45d3-8fb2-a2fbdeb9581b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/07 15:27:06 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 17:==============>                                         (4 + 12) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_8f9577437c20, depth=5, numNodes=43, numClasses=8, numFeatures=54\n",
      "  If (feature 0 <= 3046.5)\n",
      "   If (feature 0 <= 2481.5)\n",
      "    If (feature 3 <= 15.0)\n",
      "     If (feature 12 <= 0.5)\n",
      "      If (feature 23 <= 0.5)\n",
      "       Predict: 4.0\n",
      "      Else (feature 23 > 0.5)\n",
      "       Predict: 3.0\n",
      "     Else (feature 12 > 0.5)\n",
      "      Predict: 6.0\n",
      "    Else (feature 3 > 15.0)\n",
      "     If (feature 16 <= 0.5)\n",
      "      Predict: 3.0\n",
      "     Else (feature 16 > 0.5)\n",
      "      If (feature 9 <= 1305.5)\n",
      "       Predict: 3.0\n",
      "      Else (feature 9 > 1305.5)\n",
      "       Predict: 4.0\n",
      "   Else (feature 0 > 2481.5)\n",
      "    If (feature 17 <= 0.5)\n",
      "     If (feature 15 <= 0.5)\n",
      "      Predict: 2.0\n",
      "     Else (feature 15 > 0.5)\n",
      "      Predict: 3.0\n",
      "    Else (feature 17 > 0.5)\n",
      "     If (feature 0 <= 2702.5)\n",
      "      Predict: 3.0\n",
      "     Else (feature 0 > 2702.5)\n",
      "      If (feature 5 <= 1227.0)\n",
      "       Predict: 5.0\n",
      "      Else (feature 5 > 1227.0)\n",
      "       Predict: 2.0\n",
      "  Else (feature 0 > 3046.5)\n",
      "   If (feature 0 <= 3316.5)\n",
      "    If (feature 7 <= 240.5)\n",
      "     Predict: 1.0\n",
      "    Else (feature 7 > 240.5)\n",
      "     If (feature 3 <= 330.5)\n",
      "      If (feature 0 <= 3183.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 0 > 3183.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 3 > 330.5)\n",
      "      If (feature 0 <= 3206.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 0 > 3206.5)\n",
      "       Predict: 1.0\n",
      "   Else (feature 0 > 3316.5)\n",
      "    If (feature 12 <= 0.5)\n",
      "     If (feature 4 <= 35.5)\n",
      "      If (feature 1 <= 123.5)\n",
      "       Predict: 7.0\n",
      "      Else (feature 1 > 123.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 4 > 35.5)\n",
      "      Predict: 1.0\n",
      "    Else (feature 12 > 0.5)\n",
      "     If (feature 45 <= 0.5)\n",
      "      Predict: 7.0\n",
      "     Else (feature 45 > 0.5)\n",
      "      If (feature 5 <= 930.5)\n",
      "       Predict: 7.0\n",
      "      Else (feature 5 > 930.5)\n",
      "       Predict: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(seed = 1234, labelCol= 'Cover_Type', featuresCol= 'featureVector', predictionCol= 'prediction')\n",
    "model = classifier.fit(assembled_train)\n",
    "print(model.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e7667d-c10d-4e02-b5de-8ea826766dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    importance\n",
      "Elevation                             0.829831\n",
      "Soil_Type3                            0.040651\n",
      "Soil_Type1                            0.032267\n",
      "Hillshade_Noon                        0.026839\n",
      "Horizontal_Distance_To_Hydrology      0.019267\n",
      "Soil_Type31                           0.018413\n",
      "Wilderness_Area_2                     0.015613\n",
      "Horizontal_Distance_To_Roadways       0.004735\n",
      "Vertical_Distance_To_Hydrology        0.003614\n",
      "Soil_Type2                            0.003604\n",
      "Horizontal_Distance_To_Fire_Points    0.002298\n",
      "Aspect                                0.001801\n",
      "Soil_Type9                            0.001067\n",
      "Slope                                 0.000000\n",
      "Wilderness_Area_3                     0.000000\n",
      "Wilderness_Area_1                     0.000000\n",
      "Wilderness_Area_0                     0.000000\n",
      "Soil_Type0                            0.000000\n",
      "Soil_Type4                            0.000000\n",
      "Soil_Type5                            0.000000\n",
      "Hillshade_3pm                         0.000000\n",
      "Hillshade_9am                         0.000000\n",
      "Soil_Type7                            0.000000\n",
      "Soil_Type6                            0.000000\n",
      "Soil_Type10                           0.000000\n",
      "Soil_Type8                            0.000000\n",
      "Soil_Type12                           0.000000\n",
      "Soil_Type13                           0.000000\n",
      "Soil_Type14                           0.000000\n",
      "Soil_Type11                           0.000000\n",
      "Soil_Type16                           0.000000\n",
      "Soil_Type17                           0.000000\n",
      "Soil_Type18                           0.000000\n",
      "Soil_Type19                           0.000000\n",
      "Soil_Type20                           0.000000\n",
      "Soil_Type21                           0.000000\n",
      "Soil_Type22                           0.000000\n",
      "Soil_Type15                           0.000000\n",
      "Soil_Type23                           0.000000\n",
      "Soil_Type24                           0.000000\n",
      "Soil_Type26                           0.000000\n",
      "Soil_Type25                           0.000000\n",
      "Soil_Type27                           0.000000\n",
      "Soil_Type28                           0.000000\n",
      "Soil_Type29                           0.000000\n",
      "Soil_Type30                           0.000000\n",
      "Soil_Type32                           0.000000\n",
      "Soil_Type33                           0.000000\n",
      "Soil_Type34                           0.000000\n",
      "Soil_Type35                           0.000000\n",
      "Soil_Type36                           0.000000\n",
      "Soil_Type37                           0.000000\n",
      "Soil_Type38                           0.000000\n",
      "Soil_Type39                           0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(model.featureImportances.toArray(), index= input_cols, columns= ['importance']).sort_values(by= 'importance', ascending= False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b3df7-4f40-4022-a3d3-0e6516b688ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
